from __future__ import annotations

from dataclasses import dataclass
from functools import partial
from typing import Annotated, Any, Dict, List, Literal, TypedDict

from pydantic import BaseModel, Field

from langchain.tools import tool
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage, ToolMessage
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

from integrator import GRAMMO_LARK_SPEC

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except Exception as e:  # pragma: no cover
    ChatGoogleGenerativeAI = None




class RunTestsInput(BaseModel):
    code: str = Field(description="Grammo program source code")
    tests: str = Field(description="Test plan or test cases generated by the tester")


@tool("run_grammo_tests", args_schema=RunTestsInput)
def run_grammo_tests(code: str, tests: str) -> Dict[str, Any]:
    """
    Run Grammo tests against provided source code.

    Parameters
    ----------
    code : str
        Source code to be tested (e.g., module source or program text).
    tests : str
        Test definitions or test-suite content (e.g., test cases, assertions, or
        commands) that the runner will execute against `code`.

    Returns
    -------
    Dict[str, Any]
        Result dictionary containing at minimum:
        - "passed" (bool): True if all tests passed, False otherwise.
        - "stdout" (str): Captured standard output from the test run.
        - "stderr" (str): Captured standard error from the test run.
        Additional keys may be added by real implementations (e.g., detailed
        failure reports, execution time, exit codes).

    Raises
    ------
    ValueError
        If `code` or `tests` are empty or otherwise invalid.
    RuntimeError
        If the test execution environment cannot be initialized or the runner
        encounters an unexpected internal error.

    Notes
    -----
    This function is currently a placeholder; replace with real integration to your
    toolchain to execute tests and collect results.
    """
    """"""
    # TODO: implement real test execution against your toolchain.
    return {"passed": True, "stdout": "", "stderr": ""}


TOOLS = [run_grammo_tests]


class TesterState(TypedDict, total=False):
    messages: Annotated[List[BaseMessage], add_messages]
    code: str
    tests: str
    test_result: Dict[str, Any]


TESTER_SYSTEM = SystemMessage(
    content=(
        "You are TESTER.\n"
        "Input: a Grammo program.\n"
        "Goal: create a compact, effective set of tests and run them.\n\n"
        "Rules:\n"
        "- FOLLOW THE GRAMMO LARK SPEC EXACTLY (see below).\n"
        "- Generate tests as plain text (a clear test plan with inputs/expected outputs).\n"
        "- You MUST call the tool `run_grammo_tests` exactly once with BOTH:\n"
        "  - code: the full Grammo source\n"
        "  - tests: the test plan you generated\n"
        "- After the tool call, summarize results briefly.\n\n"
        "LARK SPECIFICATION:\n"
        f"{GRAMMO_LARK_SPEC}"
    )
)


@dataclass(frozen=True)
class TesterContext:
    llm_with_tools: object


def build_gemini_llm(model: str = "gemini-2.5-pro") -> object:
    if ChatGoogleGenerativeAI is None:
        raise RuntimeError(
            "Missing dependency: langchain-google-genai. Install it and set GOOGLE_API_KEY."
        )
    return ChatGoogleGenerativeAI(model=model, temperature=0)


def tester_generate(ctx: TesterContext, state: TesterState) -> Dict:
    code = (state.get("code") or "").strip()
    msgs = state.get("messages", [])
    if not msgs:
        msgs = [TESTER_SYSTEM, HumanMessage(content="No input provided.")]

    if not any(isinstance(m, SystemMessage) for m in msgs):
        msgs = [TESTER_SYSTEM, *msgs]

    if code and not any(isinstance(m, HumanMessage) and "GRAMMO CODE:" in (m.content or "") for m in msgs):
        msgs = [
            *msgs,
            HumanMessage(content=f"GRAMMO CODE:\n{code}\n\nGenerate tests and call run_grammo_tests."),
        ]

    ai: AIMessage = ctx.llm_with_tools.invoke(msgs)
    return {"messages": [ai]}


def tester_route(state: TesterState) -> Literal["tools", "__end__"]:
    msgs = state.get("messages", [])
    if not msgs:
        return "__end__"
    last = msgs[-1]
    if getattr(last, "tool_calls", None):
        return "tools"
    return "__end__"


def tester_collect(state: TesterState) -> Dict:
    msgs = state.get("messages", [])
    tests_text = ""
    result: Dict[str, Any] = {}
    for m in msgs:
        if isinstance(m, ToolMessage) and (m.name == "run_grammo_tests"):
            try:
                result = m.content if isinstance(m.content, dict) else result
            except Exception:
                pass
    if msgs and isinstance(msgs[-1], AIMessage):
        tests_text = (msgs[-1].content or "").strip()
    return {"tests": tests_text, "test_result": result}


def build_tester_graph(gemini_model: str = "gemini-1.5-pro"):
    llm = build_gemini_llm(model=gemini_model)
    ctx = TesterContext(llm_with_tools=llm.bind_tools(TOOLS))

    g = StateGraph(TesterState)
    g.add_node("generate", partial(tester_generate, ctx))
    g.add_node("tools", ToolNode(TOOLS))
    g.add_node("collect", tester_collect)

    g.add_edge(START, "generate")
    g.add_conditional_edges("generate", tester_route, {"tools": "tools", "__end__": END})
    g.add_edge("tools", "collect")
    g.add_edge("collect", END)

    return g.compile()
